{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4sLmjIuDpmY"
      },
      "source": [
        "![](https://storage.googleapis.com/kaggle-competitions/kaggle/10338/logos/header.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3veiK-TXoGSV"
      },
      "source": [
        "Today, we'll use neural networks for pneumonia detection! We'll practice creating toy neural networks, apply neural networks (including Convolutional Neural Nets!) to our pneumonia data, and experiment with *transfer learning*: learning from an existing \"expert network\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsa9kzHFh4yU"
      },
      "source": [
        "In this notebook we'll be:\n",
        "1.   Building Neural Networks with Keras\n",
        "2.   Implementing Transfer Learning\n",
        "3.   Evalulating our ML models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMoymbJeqib4",
        "outputId": "719aeab1-dcc4-45db-8c58-7382aec42ad4"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.0' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/kanis/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def augment(data, augmenter):\n",
        "  if len(data.shape) == 3:\n",
        "    return augmenter.augment_image(data)\n",
        "  if len(data.shape) == 4:\n",
        "    return augmenter.augment_images(data)\n",
        "\n",
        "def rotate(data, rotate):\n",
        "  fun = augmenters.Affine(rotate = rotate)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def shear(data, shear):\n",
        "  fun = augmenters.Affine(shear = shear)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def scale(data, scale):\n",
        "  fun = augmenters.Affine(scale = shear)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def flip_left_right(data):\n",
        "  fun = augmenters.Fliplr()\n",
        "  return augment(data, fun)\n",
        "\n",
        "def flip_up_down(data):\n",
        "  fun = augmenters.Flipud()\n",
        "  return augment(data, fun)\n",
        "\n",
        "def remove_color(data, channel):\n",
        "  new_data = data.copy()\n",
        "  if len(data.shape) == 3:\n",
        "    new_data[:,:,channel] = 0\n",
        "    return new_data\n",
        "  if len(data.shape) == 4:\n",
        "    new_data[:,:,:,channel] = 0\n",
        "    return new_data\n",
        "\n",
        "class pkg:\n",
        "  #### DOWNLOADING AND LOADING DATA\n",
        "  def get_metadata(metadata_path, which_splits = ['train', 'test']):\n",
        "    '''returns metadata dataframe which contains columns of:\n",
        "       * index: index of data into numpy data\n",
        "       * class: class of image\n",
        "       * split: which dataset split is this a part of?\n",
        "    '''\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    keep_idx = metadata['split'].isin(which_splits)\n",
        "    return metadata[keep_idx]\n",
        "\n",
        "  def get_data_split(split_name, flatten, all_data, metadata, image_shape):\n",
        "    '''\n",
        "    returns images (data), labels from folder of format [image_folder]/[split_name]/[class_name]/\n",
        "    flattens if flatten option is True\n",
        "    '''\n",
        "    sub_df = metadata[metadata['split'].isin([split_name])]\n",
        "    index  = sub_df['index'].values\n",
        "    labels = sub_df['class'].values\n",
        "    data = all_data[index,:]\n",
        "    if flatten:\n",
        "      data = data.reshape([-1, np.product(image_shape)])\n",
        "    return data, labels\n",
        "\n",
        "  def get_train_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('train', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_test_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('test', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_field_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('field', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "class helpers:\n",
        "  #### PLOTTING\n",
        "  def plot_one_image(data, labels = [], index = None, image_shape = [64,64,3]):\n",
        "    '''\n",
        "    if data is a single image, display that image\n",
        "\n",
        "    if data is a 4d stack of images, display that image\n",
        "    '''\n",
        "    num_dims   = len(data.shape)\n",
        "    num_labels = len(labels)\n",
        "\n",
        "    # reshape data if necessary\n",
        "    if num_dims == 1:\n",
        "      data = data.reshape(target_shape)\n",
        "    if num_dims == 2:\n",
        "      data = data.reshape(np.vstack[-1, image_shape])\n",
        "    num_dims   = len(data.shape)\n",
        "\n",
        "    # check if single or multiple images\n",
        "    if num_dims == 3:\n",
        "      if num_labels > 1:\n",
        "        print('Multiple labels does not make sense for single image.')\n",
        "        return\n",
        "\n",
        "      label = labels\n",
        "      if num_labels == 0:\n",
        "        label = ''\n",
        "      image = data\n",
        "\n",
        "    if num_dims == 4:\n",
        "      image = data[index, :]\n",
        "      label = labels[index]\n",
        "\n",
        "    # plot image of interest\n",
        "    print('Label: %s'%label)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "  #### QUERYING AND COMBINING DATA\n",
        "  def get_misclassified_data(data, labels, predictions):\n",
        "    '''\n",
        "    Gets the data and labels that are misclassified in a classification task\n",
        "    Returns:\n",
        "    -missed_data\n",
        "    -missed_labels\n",
        "    -predicted_labels (corresponding to missed_labels)\n",
        "    -missed_index (indices of items in original dataset)\n",
        "    '''\n",
        "    missed_index     = np.where(np.abs(predictions.squeeze() - labels.squeeze()) > 0)[0]\n",
        "    missed_labels    = labels[missed_index]\n",
        "    missed_data      = data[missed_index,:]\n",
        "    predicted_labels = predictions[missed_index]\n",
        "    return missed_data, missed_labels, predicted_labels, missed_index\n",
        "\n",
        "  def combine_data(data_list, labels_list):\n",
        "    return np.concatenate(data_list, axis = 0), np.concatenate(labels_list, axis = 0)\n",
        "\n",
        "  def model_to_string(model):\n",
        "    import re\n",
        "    stringlist = []\n",
        "    model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "    sms = \"\\n\".join(stringlist)\n",
        "    sms = re.sub('_\\d\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d','', sms)\n",
        "    return sms\n",
        "\n",
        "  def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    # i'm sorry for this function's code. i am so sorry.\n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')\n",
        "    ax.legend(loc = 1)\n",
        "    ax.set_ylim([0.4, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "class models:\n",
        "  def DenseClassifier(hidden_layer_sizes, nn_params, dropout = 0.3):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape = nn_params['input_shape']))\n",
        "    for ilayer in hidden_layer_sizes:\n",
        "      model.add(Dense(ilayer, activation = 'relu'))\n",
        "      if dropout:\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.95),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def CNNClassifier(num_hidden_layers, nn_params, dropout = 0.3):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=nn_params['input_shape'], padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    for i in range(num_hidden_layers-1):\n",
        "        model.add(Conv2D(32, (3, 3), padding = 'same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(units = 128, activation = 'relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Dense(units = 64, activation = 'relu'))\n",
        "\n",
        "\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = keras.optimizers.RMSprop(learning_rate=1e-4, decay=1e-6)\n",
        "\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def TransferClassifier(name, nn_params, trainable = True):\n",
        "    expert_dict = {'VGG16': VGG16,\n",
        "                   'VGG19': VGG19,\n",
        "                   'ResNet50':ResNet50,\n",
        "                   'DenseNet121':DenseNet121}\n",
        "\n",
        "    expert_conv = expert_dict[name](weights = 'imagenet',\n",
        "                                              include_top = False,\n",
        "                                              input_shape = nn_params['input_shape'])\n",
        "    for layer in expert_conv.layers:\n",
        "      layer.trainable = trainable\n",
        "\n",
        "    expert_model = Sequential()\n",
        "    expert_model.add(expert_conv)\n",
        "    expert_model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    expert_model.add(Dense(128, activation = 'relu'))\n",
        "    expert_model.add(Dropout(0.3))\n",
        "\n",
        "    expert_model.add(Dense(64, activation = 'relu'))\n",
        "\n",
        "    expert_model.add(Dense(nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    expert_model.compile(loss = nn_params['loss'],\n",
        "                  optimizer = optimizers.SGD(lr=1e-4, momentum=0.95),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return expert_model\n",
        "\n",
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import model_selection\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.optimizers as optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.densenet import DenseNet121\n",
        "\n",
        "from imgaug import augmenters\n",
        "\n",
        "### defining project variables\n",
        "# file variables\n",
        "metadata_url         = \"https://storage.googleapis.com/training-labs/metadata.csv\"\n",
        "image_data_url       = 'https://storage.googleapis.com/training-labs/image_data.npy'\n",
        "image_data_path      = './image_data.npy'\n",
        "metadata_path        = './metadata.csv'\n",
        "image_shape          = (64, 64, 3)\n",
        "\n",
        "# neural net parameters\n",
        "nn_params = {}\n",
        "nn_params['input_shape']       = image_shape\n",
        "nn_params['output_neurons']    = 1\n",
        "nn_params['loss']              = 'binary_crossentropy'\n",
        "nn_params['output_activation'] = 'sigmoid'\n",
        "\n",
        "###\n",
        "# gdown.download(image_data_url, './image_data.npy', True)\n",
        "# gdown.download(metadata_url, './metadata.csv', True)\n",
        "!wget \"https://storage.googleapis.com/training-labs/metadata.csv\"\n",
        "!wget \"https://storage.googleapis.com/training-labs/image_data.npy\"\n",
        "\n",
        "### pre-loading all data of interest\n",
        "_all_data = np.load('image_data.npy')\n",
        "_metadata = pkg.get_metadata(metadata_path, ['train','test','field'])\n",
        "\n",
        "### preparing definitions\n",
        "# downloading and loading data\n",
        "get_data_split = pkg.get_data_split\n",
        "get_metadata    = lambda :                 pkg.get_metadata(metadata_path, ['train','test'])\n",
        "get_train_data  = lambda flatten = False : pkg.get_train_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_test_data   = lambda flatten = False : pkg.get_test_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_field_data  = lambda flatten = False : pkg.get_field_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "\n",
        "# plotting\n",
        "plot_one_image = lambda data, labels = [], index = None: helpers.plot_one_image(data = data, labels = labels, index = index, image_shape = image_shape);\n",
        "plot_acc       = lambda history: helpers.plot_acc(history)\n",
        "\n",
        "# querying and combining data\n",
        "model_to_string        = lambda model: helpers.model_to_string(model)\n",
        "get_misclassified_data = helpers.get_misclassified_data;\n",
        "combine_data           = helpers.combine_data;\n",
        "\n",
        "# models with input parameters\n",
        "DenseClassifier     = lambda hidden_layer_sizes: models.DenseClassifier(hidden_layer_sizes = hidden_layer_sizes, nn_params = nn_params);\n",
        "CNNClassifier       = lambda num_hidden_layers: models.CNNClassifier(num_hidden_layers, nn_params = nn_params);\n",
        "TransferClassifier  = lambda name: models.TransferClassifier(name = name, nn_params = nn_params);\n",
        "\n",
        "monitor = ModelCheckpoint('./model.h5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RPBpLbngIZO"
      },
      "source": [
        "# **Milestone 1. Learning Neural Networks**\n",
        "\n",
        "Now, let's apply neural networks to our medical imaging problem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYqvCKWpKfRM"
      },
      "source": [
        "### What are neural networks?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q9S6SDcM8N9"
      },
      "source": [
        "Each orange and blue node is a neuron. The network itself is composed of a bunch of neurons that talk to each other and eventually give us a prediction. Let's get a bit more concrete with this..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E--8mjToZYBp"
      },
      "source": [
        "To build neural networks in Python, we use the packages known as `tensorflow` and `keras`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqFAnQCxsgRm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq4G0hDwZKnM"
      },
      "source": [
        "## Exercise (Coding): A 2-Layer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj-Pt3wGCXRu"
      },
      "source": [
        "\n",
        "We're going to build this model:\n",
        "\n",
        "![](http://cs231n.github.io/assets/nn1/neural_net.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-6WGeedvTCS"
      },
      "source": [
        "This network can be described as:\n",
        "* Input Layer: 3\n",
        "* Layer 1 (Hidden): 4 neurons with the `'relu'` activation function\n",
        "* Layer 2 (Output): 2 neurons with the `'linear'` activation function\n",
        "\n",
        "We're going to set up a **Sequential** model by adding on a sequence of layers.\n",
        "\n",
        "Each layer will be **Dense**, meaning each neuron of the previous layer connects to each neuron of this layer.\n",
        "\n",
        "We'll compile our model to make it ready to use! We'll use:\n",
        "- `loss = 'binary_crossentropy'` (how to measure the model's performance while it trains)\n",
        "- `optimizer = 'adam'` (an algorithm for adjusting the weights)\n",
        "- `metric = 'accuracy'` (how to measure the model's performance at the end)\n",
        "\n",
        "Try it out below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlVFP9lhJed-"
      },
      "outputs": [],
      "source": [
        "model_1_answer = Sequential()\n",
        "model_1_answer.add(Dense(4, input_shape = (3,), activation = 'relu'))\n",
        "model_1_answer.add(Dense(2, activation = 'linear'))\n",
        "model_1_answer.compile(loss='binary_crossentropy',\n",
        "optimizer = 'adam',\n",
        "metrics = ['accuracy'])\n",
        "model_1 = model_1_answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH2UGOK4vuZ4",
        "outputId": "677fd6c4-2ed7-4e44-cb46-b770a07aff3c"
      },
      "outputs": [],
      "source": [
        "model_1_answer = Sequential()\n",
        "model_1_answer.add(Dense(4, input_shape = (3,), activation = 'relu'))\n",
        "model_1_answer.add(Dense(2, activation = 'linear'))\n",
        "model_1_answer.compile(loss='binary_crossentropy',\n",
        "optimizer = 'adam',\n",
        "metrics = ['accuracy'])\n",
        "\n",
        "model_1_config = model_1.get_config()\n",
        "\n",
        "del model_1_config[\"name\"]\n",
        "for layer in model_1_config[\"layers\"]:\n",
        "  del layer[\"config\"][\"name\"]\n",
        "\n",
        "model_1_answer_config = model_1_answer.get_config()\n",
        "\n",
        "del model_1_answer_config[\"name\"]\n",
        "for layer in model_1_answer_config[\"layers\"]:\n",
        "  del layer[\"config\"][\"name\"]\n",
        "\n",
        "if model_1_answer_config == model_1_config:\n",
        "  print('Good job! Your model worked')\n",
        "else:\n",
        "  print('Please check your code again!')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNBg8obslWlo"
      },
      "source": [
        "This is a toy example, so we won't train our model with real data - but we can feed in some fake inputs to see what happens! **How many inputs do we need?**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBfMgsO5mwlp"
      },
      "outputs": [],
      "source": [
        "\n",
        "input_data = [[[3,4,3]]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJMbtRllotiY"
      },
      "source": [
        "Let's try it out! What do **predict** and **predict_classes** do? How do you interpret the outputs?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIiU4_ngotGh",
        "outputId": "9c306c53-2fda-4fcb-d2fb-19985d5e467f"
      },
      "outputs": [],
      "source": [
        "input_data = np.array(input_data)\n",
        "input_data = input_data.reshape(-1, 3)\n",
        "\n",
        "print(model_1.predict(input_data))\n",
        "print((model_1.predict(input_data) > 0.5).astype(\"int32\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9CmrRkgT5ZS"
      },
      "source": [
        "# **Milestone 2. Exploring Neural Networks**\n",
        "\n",
        "Now, let's apply neural networks to our medical imaging problem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD3Z0QamJF68"
      },
      "source": [
        "\n",
        "In our problem, we are given `images` of shape `(64,64,3)`, each assigned a label PNEUMONIA or HEALTHY. We want to identify the key things that we need to design our network.\n",
        "\n",
        "Understand these points:\n",
        "\n",
        "* What are our inputs?\n",
        "* What is/are our outputs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_6dLetSokDU"
      },
      "source": [
        "**Here are the steps to creating a neural network:**\n",
        "\n",
        "1. Ready the training data/labels and testing data/labels\n",
        "2. Initiate a model using a certain classifier\n",
        "3. Train the model using the training data and labels\n",
        "4. Predict the outputs using the test data\n",
        "5. Score the model by comparing the test labels with the predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hycYYZIorCS6"
      },
      "source": [
        "**Here is an example of code that creates a neural network, with comments:**\n",
        "\n",
        "This neural network uses Scikit-learn (used for regression problems). [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) is a type of neural network algorithm, so you can create a simple neural network! Click on the hyperlink to learn more about them if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYm6_QGUqmTN",
        "outputId": "d5947d0d-19f7-4cf3-d138-92edd1db493d"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "(train_data, train_labels) = get_train_data(flatten = True);\n",
        "(test_data, test_labels) = get_test_data(flatten = True);\n",
        "model = MLPClassifier(hidden_layer_sizes=(5))\n",
        "model.fit(train_data,train_labels)\n",
        "predictions = model.predict(test_data)\n",
        "score = accuracy_score(test_labels, predictions)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqtEHLIyvu_C"
      },
      "source": [
        "# **Milestone 3. Diving Deeper into Neural Networks**\n",
        "\n",
        "Now, let's explore more complex neural networks and apply them to our medical imaging problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47bngTjCT_pM"
      },
      "source": [
        "Let's try out 'Convolutional Neural Networks'! [Convolutional neural networks](https://www.tensorflow.org/tutorials/images/cnn) are networks that process images much like our visual system does. Click on the hyperlink to learn more about them if you want.\n",
        "\n",
        "We'll use a Keras wrapper that abstracts away the details.\n",
        "\n",
        "First, let's get our data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeA8gWV6sqai"
      },
      "outputs": [],
      "source": [
        "train_data, train_labels = get_train_data()\n",
        "test_data, test_labels = get_test_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01ayM3u3sXA-"
      },
      "source": [
        "### Creating Models\n",
        "Now, let's create a model. In fact, let's create two:\n",
        "\n",
        "\n",
        "**For a \"vanilla\" neural network:**\n",
        "\n",
        "```\n",
        "dense = DenseClassifier(hidden_layer_sizes = (64,32))\n",
        "```\n",
        "Arguments:\n",
        "* hidden_layer_sizes: the number of neurons in each hidden layer\n",
        "* epochs: the number of times that our network trains on the whole training manual\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**For a convolutional neural network:**\n",
        "```\n",
        "cnn = CNNClassifier(num_hidden_layers = 1)\n",
        "```\n",
        "Arguments:\n",
        "* num_hidden_layers: the number of hidden layers\n",
        "\n",
        "**Create your models below!** Use any hidden layer sizes you like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTb16LvwtGNW",
        "outputId": "202bf03b-5525-493f-93d1-5100f0c473e8"
      },
      "outputs": [],
      "source": [
        "dense = DenseClassifier(hidden_layer_sizes = (64,32))\n",
        "cnn = CNNClassifier(num_hidden_layers = 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1QMuD5ttS7T"
      },
      "outputs": [],
      "source": [
        "\n",
        "dense = DenseClassifier(hidden_layer_sizes = (64,32))\n",
        "cnn = CNNClassifier(num_hidden_layers = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIFymjNnsNPC"
      },
      "source": [
        "### Fitting and Scoring\n",
        "Now, let's fit  our models!\n",
        "\n",
        "There are default parameters to `.fit` you can call:\n",
        "\n",
        "```\n",
        "model_history = model.fit(train_data, train_labels, epochs = 100, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n",
        "```\n",
        "\n",
        "The `shuffle` parameter is important for shuffling the training data before each epoch. The `monitor` callback is used to get a view on internal states and statistics of the model during training. Please don't change these parameters!\n",
        "\n",
        "**Fit your models below!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUgtK9n6t2CU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC8fahXDthI4",
        "outputId": "fcd64823-9259-4304-d90e-82330570191d"
      },
      "outputs": [],
      "source": [
        "#@title Sample Solution\n",
        "dense_history = dense.fit(train_data, train_labels, epochs = 50, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n",
        "cnn_history = cnn.fit(train_data, train_labels, epochs = 50, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlYo20_lttEA"
      },
      "source": [
        "###Scoring\n",
        "\n",
        "Now, let's evaluate our models! To get the scores, you can use:\n",
        "```\n",
        "score = model.evaluate(test_data, test_labels, verbose=0)\n",
        "```\n",
        "\n",
        "Then `score[0]` will be test loss and `score[1]` will be test accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm4EET7BuepO",
        "outputId": "eb14927a-382a-4ce6-ace9-1ad72caeb47a"
      },
      "outputs": [],
      "source": [
        "cnn_score = cnn.evaluate(test_data, test_labels, verbose=0)\n",
        "dense_score = dense.evaluate(test_data, test_labels, verbose=0)\n",
        "print (cnn_score)\n",
        "print (dense_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozaEE78ktkyw"
      },
      "source": [
        "### Plotting\n",
        "\n",
        "A great way to understand our model better is to plot the training and test accuracy over time with `plot_acc(model_history)`.\n",
        "\n",
        "**What do you observe of the training and test accuracy over the training epochs?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 893
        },
        "id": "_nBfrnjIXzdp",
        "outputId": "31122c7b-afee-4026-9c3a-80914ba95df6"
      },
      "outputs": [],
      "source": [
        "plot_acc(dense_history)\n",
        "plot_acc(cnn_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 893
        },
        "id": "jWtppCPbvK7M",
        "outputId": "219a493b-27fb-4b82-d29d-0542d74e611a"
      },
      "outputs": [],
      "source": [
        "\n",
        "plot_acc(dense_history)\n",
        "plot_acc(cnn_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5scKiYAYE8g"
      },
      "source": [
        "\n",
        "# **Milestone 4. Expert models: Transfer learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laXN17IK23GY"
      },
      "source": [
        "For all of the machine learning we've done thus far, we've used models that were built from 'scratch'. All of these models are like newborn babies that have neither seen nor explored the world."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bx5nyzE36EQ"
      },
      "source": [
        "Unfortunately, our training manual is pretty small to all the things in the big wide world. So, just training on our manual is going to be inherently limited.\n",
        "\n",
        "\n",
        "Luckily, there are **\"experts\"** who have much more training! While these **\"experts\"** haven't seen our task, they have experience with a lot of other things. We can hand them our training manual and reasonably expect that they will pick up our task fairly quickly.\n",
        "\n",
        "In deep learning, the idea of using a model trained on another task as a starting point for your model is known as **transfer learning**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DChmzlt3ARPy"
      },
      "source": [
        "### VGG 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFtHOYI2AdSs"
      },
      "source": [
        "For our transfer learning, we're going to use 'experts' built upon the famous 'ImageNet' classification problem.\n",
        "\n",
        "In ImageNet, participants were challenged to build machine learning models that could distinguish 14 million images' categories, where there were > 20,000 categories available.\n",
        "\n",
        "Below, we see examples of 4 different categories.\n",
        "\n",
        "![](http://cs231n.github.io/assets/trainset.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-E_AiG-CFj0"
      },
      "source": [
        "One of the experts we can use is VGG 16. VGG 16 was a network that was allowed to study the 14 million images 74 times.\n",
        "\n",
        "After its studying, VGG 16 was able to guess something close to the real label (top-5 accuracy) better than a human can."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvkajtdHAbzL"
      },
      "source": [
        "![](https://cdn-images-1.medium.com/max/1600/0*V1muWIDnPVwZUuEv.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwj8o5X3D325"
      },
      "source": [
        "We're going to take an expert model like VGG16 and let it train on OUR x-rays. Hopefully, their experience with those 14 million images will help it understand pneumonia from our x-rays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-357WWC7qJJ"
      },
      "source": [
        "### Exercise (Coding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz_mVsECHvro"
      },
      "source": [
        "Let's tap an expert model to help us out with our pneumonia prediction!\n",
        "\n",
        "We provide a wrapper that lets you 'call' up and employ expert models. You can call it like...\n",
        "\n",
        "```\n",
        "transfer = TransferClassifier(name = 'VGG16')\n",
        "```\n",
        "\n",
        "The experts we have on hand are:\n",
        "* `VGG16`\n",
        "* `VGG19`\n",
        "* `ResNet50`\n",
        "* `DenseNet121`\n",
        "\n",
        "There are default arguments/parameters to model.fit you can call:\n",
        "\n",
        "`model.fit(train_data, train_labels, epochs = N, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])`\n",
        "\n",
        "The shuffle parameter is important for shuffling the training data before each epoch. The monitor callback is used to get a view on internal states and statistics of the model during training. Do not change these parameters!\n",
        "\n",
        "**Experiment with using these experts. Remember to fit and score your model, and to take a look at the training history.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0VB79BCx7tvg",
        "outputId": "c1ee8416-5ed7-4cd4-a208-b2c980461c73"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_data, train_labels = get_train_data()\n",
        "test_data, test_labels = get_test_data()\n",
        "transfer = TransferClassifier(name = 'VGG16')\n",
        "transfer.fit(train_data, train_labels, epochs = 10, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n",
        "plot_acc(transfer.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sbHqc9sVEPMo",
        "outputId": "462f3640-a7b0-4518-9b57-14228f96a3e0"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_data, train_labels = get_train_data()\n",
        "test_data, test_labels = get_test_data()\n",
        "transfer = TransferClassifier(name = 'VGG16')\n",
        "transfer.fit(train_data, train_labels, epochs = 10, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n",
        "plot_acc(transfer.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlgcvRcdyv9J"
      },
      "source": [
        "**This sample solution only uses VGG16. Now try using the other expert models.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9Qp129rNV3U"
      },
      "source": [
        "# **Milestone 5. Model Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXyQLXigDbtg"
      },
      "source": [
        "\n",
        "\n",
        "### Exercise (Coding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBbSwkgVj7gS"
      },
      "source": [
        "Set your best model to the one you have trained (e.g., the transfer learning model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmjOJCGDjsMk",
        "outputId": "49f0ca11-5413-4632-b575-c4ed2ababed7"
      },
      "outputs": [],
      "source": [
        "best_model = TransferClassifier(name='DenseNet121')\n",
        "best_model.fit(train_data, train_labels, epochs = 10, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBhDGS02VGHa"
      },
      "source": [
        "Total accuracy does not reflect all that we want to know about a model's performance. It's just one metric out of many possible metrics for evaluating models.\n",
        "\n",
        "In the case of pneumonia prediction, we may be more interested in other quantities, such as 'how accurate were we on the pneumonia category?' or 'how accurate were we on the normal category?' or 'how much of pneumonia were confused for normal?' or vice versa.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_GjNUEBMSke"
      },
      "source": [
        "Our metrics for classification can be described in terms of a 'confusion matrix', shown below.\n",
        "\n",
        "![Confusion Matrix](https://cdn-images-1.medium.com/max/1600/1*Z54JgbS4DUwWSknhDCvNTQ.png)\n",
        "\n",
        "In a confusion matrix, we think in terms of 'actual' and 'predicted values'. If we take Pneumonia = 1/Positive and Normal = 0/Negative, then **what do TP, FP, TN, and FN mean?**\n",
        "\n",
        "Answer:\n",
        "1. TP: True positive (True pneumonia): Pneumonia predicted as pneumonia\n",
        "2. TN: True negative (True normal): Normal predicted as normal\n",
        "3. FP: False positive (False pneumonia): Normal mistaken as pneumonia\n",
        "4. FN: False negative (False normal): Pneumonia mistaken as normal\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL0ns-b9GBym"
      },
      "source": [
        "The `sklearn` package makes calculating confusion matrices very quick. Its `metrics` submodule actually comes with a `confusion_matrix` tool. Let's start by grabbing that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2E5299cNEcp"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvFawPv1NIyy"
      },
      "source": [
        "To use `confusion_matrix`, we need:\n",
        "* `labels`: the labels of the data (1 - PNEUMONIA or 0 - NORMAL)\n",
        "* `predictions`: what our model thinks the labels are\n",
        "\n",
        "To get `predictions`, you'll want to use ```best_model.predict_classes(test_data)```.\n",
        "\n",
        "Please get the `predictions`, and use `accuracy_score` to print the overall test accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke5_OhU1wlpU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cLkk9eJkI3I",
        "outputId": "8a6f9eb8-f56c-4e65-df8d-bd11d4eac8b4"
      },
      "outputs": [],
      "source": [
        "\n",
        "predictions = (best_model.predict(test_data) > 0.5).astype(\"int32\")\n",
        "print('Accuracy: ', accuracy_score(test_labels, predictions)*100.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcFGwTMDkCAp"
      },
      "source": [
        "Now let's get our confusion matrix, and split it out into true positive, true negative, false positive, and false negative!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7omQvlbkSTn",
        "outputId": "a671ea0e-9de8-43df-d80e-a17c8767e406"
      },
      "outputs": [],
      "source": [
        "confusion = confusion_matrix(test_labels, predictions)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zQjmPA4w8wJ"
      },
      "source": [
        "**How do you interpret each number?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K17HWY9Iw3gA",
        "outputId": "7e6b231d-c2e3-43c9-f6d6-4b8b343ae1d7"
      },
      "outputs": [],
      "source": [
        "tp  = confusion[1][1]\n",
        "tn  = confusion[0][0]\n",
        "fp = confusion[0][1]\n",
        "fn = confusion[1][0]\n",
        "\n",
        "print('True positive: %d'%tp)\n",
        "print('True negative: %d'%tn)\n",
        "print('False positive: %d'%fp)\n",
        "print('False negative: %d'%fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKlghw6_krXL"
      },
      "source": [
        "We can visualize the confusion matrix with seaborn to make it easier for our eyes..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0Cp60eokseD"
      },
      "outputs": [],
      "source": [
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "l_Jwv2-OktLb",
        "outputId": "255e00b8-89b4-4ae4-b935-fd12bd23a2fb"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(confusion, annot = True, fmt = 'd', cbar_kws={'label':'count'});\n",
        "plt.ylabel('Actual');\n",
        "plt.xlabel('Predicted');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Tt6kTRkTvm"
      },
      "source": [
        "**Now that we have our confusion matrix, let's take a step back and think about these questions**\n",
        "\n",
        "What did our model confuse more?\n",
        "* PNEUMONIA for NORMAL or...\n",
        "* NORMAL for PNEUMONIA\n",
        "\n",
        "Why do you think it might have confused one for the other?\n",
        "\n",
        "What is more problematic? False positives or False negatives?\n",
        "\n",
        "Which of these metrics do we want to keep low?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8KmugJ_N9BQ"
      },
      "source": [
        "# End!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV85QOOGQ2xm"
      },
      "source": [
        "To recap, we learned what neural network models are, learned how to create/build them, and explored different types of neural networks. By introducing convolutions and more complex methods to our networks (making the convolutional neural networks and expert models), we can improve our models quite a lot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14rKID6MOo4N"
      },
      "source": [
        "![](https://storage.googleapis.com/kaggle-competitions/kaggle/10338/logos/header.png)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
